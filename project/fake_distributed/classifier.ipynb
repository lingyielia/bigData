{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (StructField, StringType,\n",
    "                               IntegerType, StructType)\n",
    "\n",
    "# from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Basics').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schema = [StructField('_c0', IntegerType(), True), \n",
    "               StructField('0', IntegerType(), True),\n",
    "               StructField('1', IntegerType(), True),\n",
    "               StructField('2', IntegerType(), True),\n",
    "               StructField('3', IntegerType(), True),\n",
    "               StructField('4', StringType(), True),\n",
    "               StructField('5', IntegerType(), True),\n",
    "               StructField('6', IntegerType(), True)]\n",
    "final_struc = StructType(fields = data_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(index=0, station=0, day_of_week=4, time_of_day=0, net_flow=2488, date='1012016', num_of_incid=0, incid_in_effect=0),\n",
       " Row(index=1, station=0, day_of_week=0, time_of_day=2, net_flow=-6066, date='1042016', num_of_incid=0, incid_in_effect=0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv('clean_input_sample.csv', header=True, schema=final_struc)\n",
    "df = df.withColumnRenamed('_c0', 'index') \\\n",
    "        .withColumnRenamed('0', 'station') \\\n",
    "        .withColumnRenamed('1', 'day_of_week') \\\n",
    "        .withColumnRenamed('2', 'time_of_day') \\\n",
    "        .withColumnRenamed('3', 'net_flow') \\\n",
    "        .withColumnRenamed('4', 'date') \\\n",
    "        .withColumnRenamed('5', 'num_of_incid') \\\n",
    "        .withColumnRenamed('6', 'incid_in_effect')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: integer (nullable = true)\n",
      " |-- station: integer (nullable = true)\n",
      " |-- day_of_week: integer (nullable = true)\n",
      " |-- time_of_day: integer (nullable = true)\n",
      " |-- net_flow: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- num_of_incid: integer (nullable = true)\n",
      " |-- incid_in_effect: integer (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols = ['day_of_week',\n",
    "                            'time_of_day', 'net_flow'], \n",
    "                            outputCol = 'features')\n",
    "output = assembler.transform(df)\n",
    "output.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------------+\n",
      "|         features|incid_in_effect|\n",
      "+-----------------+---------------+\n",
      "| [4.0,0.0,2488.0]|              0|\n",
      "|[0.0,2.0,-6066.0]|              0|\n",
      "|[1.0,2.0,-6975.0]|              0|\n",
      "|[2.0,2.0,-6740.0]|              0|\n",
      "| [3.0,0.0,5058.0]|              0|\n",
      "| [4.0,0.0,5198.0]|              0|\n",
      "| [5.0,0.0,3362.0]|              0|\n",
      "| [6.0,4.0,4616.0]|              0|\n",
      "| [0.0,1.0,-152.0]|              1|\n",
      "| [1.0,1.0,1016.0]|              0|\n",
      "|   [2.0,1.0,82.0]|              0|\n",
      "|  [3.0,1.0,100.0]|              0|\n",
      "|  [5.0,3.0,386.0]|              0|\n",
      "|  [6.0,3.0,650.0]|              0|\n",
      "| [0.0,0.0,2258.0]|              0|\n",
      "| [1.0,0.0,4678.0]|              0|\n",
      "|[2.0,4.0,11070.0]|              0|\n",
      "|[3.0,4.0,11018.0]|              0|\n",
      "|[4.0,2.0,-5860.0]|              0|\n",
      "|[5.0,2.0,-1720.0]|              0|\n",
      "+-----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data = output.select('features', 'incid_in_effect')\n",
    "final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureIndexer = VectorIndexer(inputCol=\"features\",\n",
    "                               outputCol=\"indexedFeatures\",\n",
    "                               maxCategories=7).fit(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, test_data) = final_data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|summary|     incid_in_effect|\n",
      "+-------+--------------------+\n",
      "|  count|               24021|\n",
      "|   mean|0.006078015070146955|\n",
      "| stddev| 0.07772595644143572|\n",
      "|    min|                   0|\n",
      "|    max|                   1|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|summary|     incid_in_effect|\n",
      "+-------+--------------------+\n",
      "|  count|                5979|\n",
      "|   mean|0.005853821709315939|\n",
      "| stddev| 0.07629238478341577|\n",
      "|    min|                   0|\n",
      "|    max|                   1|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(featuresCol = 'indexedFeatures',\n",
    "                           labelCol=\"incid_in_effect\",\n",
    "                           seed=100)\n",
    "gb = GBTClassifier(labelCol = 'incid_in_effect',\n",
    "                  featuresCol=\"indexedFeatures\",\n",
    "                  maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_pipeline = Pipeline(stages=[featureIndexer, rf])\n",
    "gb_pipeline = Pipeline(stages=[featureIndexer, gb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_model = re_pipeline.fit(train_data)\n",
    "gb_model = gb_pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rf_model.transform(test_data)\n",
    "gb_pred = gb_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_eval = BinaryClassificationEvaluator(labelCol=\"incid_in_effect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.6168453182080361\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest')\n",
    "print(bi_eval.evaluate(rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_bi_eval = BinaryClassificationEvaluator(labelCol=\"incid_in_effect\",\n",
    "                                           rawPredictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print('Gradient Boosting')\n",
    "print(gb_bi_eval.evaluate(gb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_eval = MulticlassClassificationEvaluator(labelCol='incid_in_effect', \n",
    "                                             metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9941461782906841"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_acc = acc_eval.evaluate(rf_pred)\n",
    "rf_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_eval_f1 = MulticlassClassificationEvaluator(labelCol='incid_in_effect', \n",
    "                                             metricName='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9912278593910636"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_acc_f1 = acc_eval_f1.evaluate(rf_pred)\n",
    "rf_acc_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9883266238099725"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_eval_pre = MulticlassClassificationEvaluator(labelCol='incid_in_effect', \n",
    "                                             metricName='weightedPrecision')\n",
    "rf_acc_pre = acc_eval_pre.evaluate(rf_pred)\n",
    "rf_acc_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9941461782906841"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_eval_re = MulticlassClassificationEvaluator(labelCol='incid_in_effect', \n",
    "                                             metricName='weightedRecall')\n",
    "rf_acc_re = acc_eval_re.evaluate(rf_pred)\n",
    "rf_acc_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
