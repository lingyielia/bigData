{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (StructField, StringType,\n",
    "                               IntegerType, StructType)\n",
    "\n",
    "# from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Basics').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schema = [StructField('_c0', IntegerType(), True), \n",
    "               StructField('0', IntegerType(), True),\n",
    "               StructField('1', IntegerType(), True),\n",
    "               StructField('2', IntegerType(), True),\n",
    "               StructField('3', IntegerType(), True),\n",
    "               StructField('4', StringType(), True),\n",
    "               StructField('5', IntegerType(), True),\n",
    "               StructField('6', IntegerType(), True)]\n",
    "final_struc = StructType(fields = data_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(index=0, station=0, day_of_week=4, time_of_day=0, net_flow=2488, date='1012016', num_of_incid=0, incid_in_effect=0),\n",
       " Row(index=1, station=0, day_of_week=0, time_of_day=2, net_flow=-6066, date='1042016', num_of_incid=0, incid_in_effect=0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv('clean_input_sample.csv', header=True, schema=final_struc)\n",
    "df = df.withColumnRenamed('_c0', 'index') \\\n",
    "        .withColumnRenamed('0', 'station') \\\n",
    "        .withColumnRenamed('1', 'day_of_week') \\\n",
    "        .withColumnRenamed('2', 'time_of_day') \\\n",
    "        .withColumnRenamed('3', 'net_flow') \\\n",
    "        .withColumnRenamed('4', 'date') \\\n",
    "        .withColumnRenamed('5', 'num_of_incid') \\\n",
    "        .withColumnRenamed('6', 'incid_in_effect')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: integer (nullable = true)\n",
      " |-- station: integer (nullable = true)\n",
      " |-- day_of_week: integer (nullable = true)\n",
      " |-- time_of_day: integer (nullable = true)\n",
      " |-- net_flow: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- num_of_incid: integer (nullable = true)\n",
      " |-- incid_in_effect: integer (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols = ['station', 'day_of_week',\n",
    "                            'time_of_day', 'num_of_incid',\n",
    "                            'incid_in_effect'], \n",
    "                            outputCol = 'features')\n",
    "output = assembler.transform(df)\n",
    "output.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|            features|net_flow|\n",
      "+--------------------+--------+\n",
      "|       (5,[1],[4.0])|    2488|\n",
      "|       (5,[2],[2.0])|   -6066|\n",
      "| (5,[1,2],[1.0,2.0])|   -6975|\n",
      "| (5,[1,2],[2.0,2.0])|   -6740|\n",
      "|       (5,[1],[3.0])|    5058|\n",
      "|       (5,[1],[4.0])|    5198|\n",
      "|       (5,[1],[5.0])|    3362|\n",
      "| (5,[1,2],[6.0,4.0])|    4616|\n",
      "|[0.0,0.0,1.0,1.0,...|    -152|\n",
      "| (5,[1,2],[1.0,1.0])|    1016|\n",
      "| (5,[1,2],[2.0,1.0])|      82|\n",
      "| (5,[1,2],[3.0,1.0])|     100|\n",
      "| (5,[1,2],[5.0,3.0])|     386|\n",
      "| (5,[1,2],[6.0,3.0])|     650|\n",
      "|           (5,[],[])|    2258|\n",
      "|       (5,[1],[1.0])|    4678|\n",
      "| (5,[1,2],[2.0,4.0])|   11070|\n",
      "| (5,[1,2],[3.0,4.0])|   11018|\n",
      "| (5,[1,2],[4.0,2.0])|   -5860|\n",
      "| (5,[1,2],[5.0,2.0])|   -1720|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data = output.select('features', 'net_flow')\n",
    "final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureIndexer = VectorIndexer(inputCol=\"features\",\n",
    "                               outputCol=\"indexedFeatures\",\n",
    "                               maxCategories=7).fit(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, test_data) = final_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|          net_flow|\n",
      "+-------+------------------+\n",
      "|  count|             21144|\n",
      "|   mean| 662.6977393113885|\n",
      "| stddev|2684.4736844061204|\n",
      "|    min|            -21476|\n",
      "|    max|             27975|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|          net_flow|\n",
      "+-------+------------------+\n",
      "|  count|              8856|\n",
      "|   mean| 641.8454155374887|\n",
      "| stddev|2624.7603781545367|\n",
      "|    min|            -17266|\n",
      "|    max|             25397|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(featuresCol = 'indexedFeatures',\n",
    "                           labelCol=\"net_flow\",\n",
    "                           seed=100)\n",
    "# gb = GBTRegressor(labelCol = 'net_flow',\n",
    "#                   featuresCol=\"indexedFeatures\",\n",
    "#                   maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[featureIndexer, rf])\n",
    "# rf_model = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_model = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on train data = 0.24448\n"
     ]
    }
   ],
   "source": [
    "predictions = rf_model.transform(train_data)\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"net_flow\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "print(\"R2 on train data = %g\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+-------------+\n",
      "|        prediction|net_flow|     features|\n",
      "+------------------+--------+-------------+\n",
      "|2559.4922198841623|    2164|    (5,[],[])|\n",
      "|2559.4922198841623|     460|(5,[0],[1.0])|\n",
      "|2559.4922198841623|     842|(5,[0],[1.0])|\n",
      "|2559.4922198841623|     900|(5,[0],[2.0])|\n",
      "|2559.4922198841623|    1730|(5,[0],[2.0])|\n",
      "+------------------+--------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"prediction\", \"net_flow\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"net_flow\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on test data = 0.24384\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"net_flow\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "print(\"R2 on test data = %g\" % r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
